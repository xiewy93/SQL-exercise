【1】python爬虫
Python爬虫利器二之Beautiful Soup的用法
http://cuiqingcai.com/1319.html

【2】学习爬虫
资料：https://www.bilibili.com/video/av9784617/index_2.html

【3】python语言开发工具选择
文本工具类：IDLE/Sublime Text
集成工具类：PyCharm/Anaconda & Spyder
小规模爬虫，爬取网页，玩转网页：Requests库
中规模爬虫，爬取系列网站，数据规模大，爬取速度快：Scrapy库
大规模爬虫，如搜索引擎：定制

【4】Requests库的安装
http://www.python-requests.org
cmd -> pip install requests

【5】Requests库的get()方法
#构造一个向服务器请求资源的Requests对象
r = requests.get(url,params=None,**kwargs)

url:拟获取页面的url链接
params:url参数，字典或字节流格式
**kwargs:12个控制访问的参数

r.status_code #返回状态，200表示成功，404否则失败
r.text #响应内容的字符串形式，即页面内容
r.encoding # 从HTTP header中猜测的内容编码方式
r.apparent_encoding # 从HTTP 中分析的内容编码方式（备选编码方式）
r.content # 内容的二进制形式

【6】爬取网页的通用代码框架
import requests

def getHTMLText(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status() #如果状态不是200，引发HTTPError异常
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return print('产生异常')

【7】HTTP协议及Requests库方法
Requests库7个主要方法：
requests.request()
requests.get()
requests.head()
requests.post()
requests.put()
requests.patch()
requests.delete()

【8】京东商品页面的爬取
import requests
url = 'http://item.jd.com/2967929.html'
try:
   r = requests.get(url)
   r.raise_for_status()
   r.encoding = r.apparent_encoding
   print(r.text[:1000])
except:
   print('爬取失败')

【9】亚马逊商品页面的爬取
import requests
url = 'http://www.amazon.cn/gp/product/B01M8L5Z3Y'
try:
   kv = {'user-agent':'Mozilla/5.0'}#模拟浏览器访问网页
   r = requests.get(url,headers=kv)
   r.raise_for_status()
   r.encoding = r.apparent_encoding
   print(r.text[1000:2000])
except:
   print('爬取失败')

【10】百度搜索关键词提交
import requests
keyword = 'Python'
try:
   kv = {'wd':keyword}#模拟浏览器访问网页
   r = requests.get('http://www.baidu.com/s',params=kv)
   print(r.request.url)
   r.raise_for_status()
   r.encoding = r.apparent_encoding
   print(len(r.text))
except:
   print('爬取失败')

【11】360搜索关键词提交
import requests
keyword = 'Python'
try:
   kv = {'q':keyword}#模拟浏览器访问网页
   r = requests.get('http://www.so.com/s',params=kv)
   print(r.request.url)
   r.raise_for_status()
   r.encoding = r.apparent_encoding
   print(len(r.text))
except:
   print('爬取失败')

【12】网络图片的爬取和存储
import requests
import os
url = ''
root = 'D://pics//'
path = root + url.split('/')[-1]
try:
   if not os.path.exists(root):
       os.mkdir(root)
   if not os.path.exists(path):
       r = requests.get(url)
       with open(path,'wb') as f:
           f.write(r.content)
           f.close()
           print('文件保存成功')
   else:
       print('文件已存在')
except:
   print('爬取失败')

【13】IP地址归属地的自动查询
import requests
url = 'http://m.ip138.com/ip.asp?ip='
try:
   r = requests.get(url+'202.204.80.112')
   r.raise_for_status()
   r.encoding = r.apparent_encoding
   print(r.text[-500:])
except:
   print('爬取失败')
   
